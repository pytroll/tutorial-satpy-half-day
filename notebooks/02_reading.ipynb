{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data with the `Scene`\n",
    "\n",
    "Satpy's main interface for working with data is the `Scene` class. We can provide the `Scene` with data files and load them with a \"reader\". In this notebook we'll explore the basic data loading and data access functionality provided by Satpy while also providing a basic introduction to xarray's `DataArray` objects and `dask` arrays.\n",
    "\n",
    "Before importing and using Satpy, we run some python code to do some initial setup. This includes turning off warnings and limiting the number of resources we use. These are precautions to make these examples work on the most machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "* Mention available_readers() in the last cell\n",
    "* Fix filenames to make sure we are getting downloaded data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../init_notebook.py\n",
    "from satpy import Scene\n",
    "from glob import glob\n",
    "\n",
    "# Get the list of GOES-16 ABI files to open\n",
    "# FIXME: filenames = glob('./data/')\n",
    "filenames = glob('/data/data/abi/20170901/*.nc')\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn = Scene(reader='abi_l1b', filenames=filenames)\n",
    "scn.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now created a `Scene` object. Under the hood Satpy has sorted the files and determined what we can access. We haven't actually loaded any data so our dict-like `Scene` object is empty. To find out what data can be loaded from the file we can use the `available_dataset_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn.available_dataset_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Scene` is telling us that we have all 16 ABI channels available to load. This list includes any product that we can load from the file that the \"abi_l1b\" reader is configured to access. If we didn't provide all of the necessary files or the data was missing from the file for some reason, that product would not be listed here.\n",
    "\n",
    "Let's pick one of these channels, load it, and look what information is provided by Satpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_channel = 'EDIT_ME'\n",
    "# my_channel = 'C01'\n",
    "scn.load([my_channel])\n",
    "# use brackets to access products like a normal dict\n",
    "scn[my_channel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray and Dask\n",
    "\n",
    "Above we see an `xarray.DataArray` object with a lot of metadata.\n",
    "There are a few elements to get familiar with when working with DataArray's from Satpy:\n",
    "\n",
    "* `dask.array<...>`: We don't see any actual imagery data. Our data is stored in a `dask` array instead of a traditional numpy array. This means our data's loading and calculations are delayed.\n",
    "* `Attributes`: A dictionary where the metadata is stored. Some is from the file, some is added by the \"abi_l1b\" reader to assist future Satpy operations. Some of the more important keys are:\n",
    "\n",
    "  * `platform_name`\n",
    "  * `sensor`\n",
    "  * `name`\n",
    "  * `wavelength`\n",
    "  * `units`\n",
    "  * `calibration`\n",
    "  * `standard_name`\n",
    "  * `start_time`\n",
    "  * `area` (more on this later)\n",
    "\n",
    "If we want to access the attributes, we use the `.attrs` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].attrs['start_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the dimension names of the data using the `.dims` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of those dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].sizes['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataArrays also provide us access to traditional numpy properties like `shape` and `ndim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although typically not needed, we can access the dask array underneath xarray's `DataArray` via the `.data` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed Calculations\n",
    "\n",
    "It usually isn't necessary to access the dask array directly because xarray will handle all normal arithmetic and numpy functions for us. An important point here is how fast these operations seem because of the delayed dask operations involved. We haven't actually done the number crunching yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel] + 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be a little confusing at first when we do operations where we want immediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.compute()` method to load the data and perform the series calculations that we've built up so far. Dask will split the data across multiple threads to compute values in parallel; handling all of the multithreading and communication for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].max().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this operation still returns a `DataArray` so we will have access to any remaining coordinates or dimensions. We can use `.values` to compute the dask array and returning the resulting numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].max().values\n",
    "# could also do:\n",
    "# scn[my_channel].max().compute().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use them like numpy arrays\n",
    "\n",
    "In most cases, Xarray's `DataArray` objects can be used just like a regular numpy array. When the actual data values are needed they will be computed. This allows us to use `DataArray` objects with other python tools with little to no extra work. Then do a simple matplotlib plot to view our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(scn[my_channel])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like numpy arrays we can slice our `DataArray`s to get data for a particular region. In later lessons we'll learn about doing this based on geographic coordinates. For now we'll use slicing and striding to show a smaller region and a lower resolution of the channel 2 (`'C02'`) product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load C02 if we haven't already\n",
    "scn.load(['C02'])\n",
    "\n",
    "plt.figure()  # create a new figure\n",
    "plt.imshow(scn['C02'][1500:2500:4, 0:1000:4])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "**Time: 5-10 minutes**\n",
    "\n",
    "Using the above examples as a guide, load additional channels, view them with matplotlib, and explore the data either by slicing/striding or by using matplotlib's interactive notebook widget (see toolbar at the bottom left of the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing alternative product versions\n",
    "\n",
    "So far we've been referring to channels by their \"name\". These names are configured in Satpy's and can differ between instruments or even generations of the same instrument. Depending on your preferences, you may want to refer to products by wavelength. Not all products have a wavelength associated with them, but for those that do Satpy is configured with a minimum, nominal, and maximum wavelength specification for the instrument. We can use any wavelength within that range to access the data when loading data with the `.load` method or after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].attrs['wavelength']  # in Âµm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.47 in scn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[0.485].attrs['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can also vary in a couple other common ways, such as resolution (ex. 1000m versus 500m), calibration (ex. reflectance versus radiance), and polarization (ex. V versus H). We can specify these when identifying products as well using a special `DatasetID` object or with keyword arguments in the `.load` method. To see a full list of the available data products we can use a new method called `Scene.available_dataset_ids`. We'll leave this as an exercise for the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolocation and Areas\n",
    "\n",
    "Until now we've been dealing with the data as an image with no relation to the Earth. In Satpy, we use a special object in the `.attrs['area']` attribute to define where the data is located.\n",
    "\n",
    "Some people prefer to use longitude and latitude coordinates when working with their data. Let's use the area to get the longitude and latitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats = scn[my_channel].attrs['area'].get_lonlats()\n",
    "lons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can take a while because by default it returns a numpy array. Let's tell it to return a dask array by specifying the `chunks=2048` keyword argument in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(scn[my_channel].attrs['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn[my_channel].attrs['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"area\" for our ABI data is an `AreaDefinition` object from the `pyresample` library. This means that are data is uniformly gridded on a projected surface. This differs from data that may be non-uniform where the only way to address it is individual longitude and latitude coordinates.\n",
    "\n",
    "We'll learn more about both of these situations in the resampling lesson later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Readers\n",
    "\n",
    "Lastly, let's explore what other readers Satpy current has. We'll use the `available_readers` function to give us a list of useable readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from satpy import available_readers\n",
    "sorted(available_readers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are missing any of the dependencies for some of Satpy's readers they won't be listed here. We can check what functionality we are missing by using `check_satpy` like we did in the Introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from satpy.config import check_satpy\n",
    "check_satpy(writers=[], extras=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
